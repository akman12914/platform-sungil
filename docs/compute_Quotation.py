# Create a Streamlit app scaffold that implements the requested estimator.
# It expects the user to upload Sungil_DB2_new.xlsx (sheet: ÏûêÏû¨Îã®Í∞ÄÎÇ¥Ïó≠)
# and three JSON files: floor_data.json, wall_data.json, ceiling_data.json.
# The code emphasizes clarity, mappings, and graceful fallbacks.

import json, textwrap, os, pandas as pd

# app.py
import json
import io
from typing import Dict, Any, List, Optional, Tuple
import pandas as pd
import streamlit as st

st.set_page_config(page_title="ÏöïÏã§ Í≤¨Ï†ÅÏÑú ÏÉùÏÑ±Í∏∞", layout="wide")

# ----------------------------
# Helpers
# ----------------------------
REQ_COLUMNS = ["ÌíàÎ™©", "Î∂ÑÎ•ò", "ÏÇ¨Ïñë Î∞è Í∑úÍ≤©", "Îã®Í∞Ä", "ÏàòÎüâ"]

@st.cache_data(show_spinner=False)
def load_pricebook_from_excel(file_bytes: bytes, sheet_name: str = "ÏûêÏû¨Îã®Í∞ÄÎÇ¥Ïó≠") -> pd.DataFrame:
    df = pd.read_excel(io.BytesIO(file_bytes), sheet_name=sheet_name)
    # Normalize columns
    colmap = {}
    for c in df.columns:
        c2 = str(c).strip()
        if c2 in ["ÌíàÎ™©","ÌèºÎ™©"]: colmap[c] = "ÌíàÎ™©"
        elif c2 in ["Î∂ÑÎ•ò"]: colmap[c] = "Î∂ÑÎ•ò"
        elif c2 in ["ÏÇ¨Ïñë Î∞è Í∑úÍ≤©", "ÏÇ¨Ïñë","Í∑úÍ≤©"]: colmap[c] = "ÏÇ¨Ïñë Î∞è Í∑úÍ≤©"
        elif c2 in ["Îã®Í∞Ä"]: colmap[c] = "Îã®Í∞Ä"
        elif c2 in ["ÏàòÎüâ"]: colmap[c] = "ÏàòÎüâ"
        elif c2 in ["Í∏àÏï°"]: colmap[c] = "Í∏àÏï°"
    df = df.rename(columns=colmap)
    # Ensure required columns exist
    for c in ["ÌíàÎ™©","Î∂ÑÎ•ò","ÏÇ¨Ïñë Î∞è Í∑úÍ≤©","Îã®Í∞Ä","ÏàòÎüâ"]:
        if c not in df.columns:
            df[c] = None
    # Clean values
    for c in ["ÌíàÎ™©","Î∂ÑÎ•ò","ÏÇ¨Ïñë Î∞è Í∑úÍ≤©"]:
        df[c] = df[c].astype(str).str.strip()
    for c in ["Îã®Í∞Ä","ÏàòÎüâ"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")
    if "Í∏àÏï°" not in df.columns:
        df["Í∏àÏï°"] = df["Îã®Í∞Ä"].fillna(0) * df["ÏàòÎüâ"].fillna(0)
    return df

def find_item(df: pd.DataFrame, ÌíàÎ™©: str, Î∂ÑÎ•ò: Optional[str]=None, spec_contains: Optional[str]=None) -> Optional[pd.Series]:
    q = (df["ÌíàÎ™©"] == ÌíàÎ™©)
    if Î∂ÑÎ•ò is not None:
        q &= (df["Î∂ÑÎ•ò"] == Î∂ÑÎ•ò)
    if spec_contains:
        q &= df["ÏÇ¨Ïñë Î∞è Í∑úÍ≤©"].str.contains(str(spec_contains), case=False, na=False)
    candidates = df[q]
    if len(candidates) == 0:
        return None
    # If multiple, prefer exact spec match first
    if spec_contains:
        exact = candidates[candidates["ÏÇ¨Ïñë Î∞è Í∑úÍ≤©"].str.strip() == spec_contains]
        if len(exact) == 1: 
            return exact.iloc[0]
    return candidates.iloc[0]

def add_row(rows: List[Dict[str,Any]], ÌíàÎ™©: str, spec: str, qty: float, unit_price: Optional[float]) -> None:
    unit_price = unit_price if unit_price is not None else 0
    amount = (qty or 0) * (unit_price or 0)
    rows.append({"ÌíàÎ™©": ÌíàÎ™©, "ÏÇ¨Ïñë Î∞è Í∑úÍ≤©": spec, "ÏàòÎüâ": qty, "Îã®Í∞Ä": unit_price, "Í∏àÏï°": amount})

def add_all_by_category(rows: List[Dict[str,Any]], df: pd.DataFrame, ÌíàÎ™©: str, Î∂ÑÎ•ò: str):
    sub = df[(df["ÌíàÎ™©"]==ÌíàÎ™©) & (df["Î∂ÑÎ•ò"]==Î∂ÑÎ•ò)]
    for _, r in sub.iterrows():
        add_row(rows, ÌíàÎ™©, str(r["ÏÇ¨Ïñë Î∞è Í∑úÍ≤©"]), r["ÏàòÎüâ"] if pd.notna(r["ÏàòÎüâ"]) else 1, r["Îã®Í∞Ä"] if pd.notna(r["Îã®Í∞Ä"]) else 0)

# ----------------------------
# UI: Uploads
# ----------------------------
st.title("üõÅ ÏöïÏã§ Í≤¨Ï†ÅÏÑú ÏÉùÏÑ±Í∏∞ (Streamlit)")

with st.sidebar:
    st.markdown("### ‚ë† Îã®Í∞ÄÌëú ÏóÖÎ°úÎìú")
    pricebook_file = st.file_uploader("Sungil_DB2_new.xlsx (ÏãúÌä∏Î™Ö: ÏûêÏû¨Îã®Í∞ÄÎÇ¥Ïó≠)", type=["xlsx"])

    st.markdown("---")
    st.markdown("### ‚ë° JSON ÏóÖÎ°úÎìú")
    floor_json = st.file_uploader("floor_data.json", type=["json"])
    wall_json = st.file_uploader("wall_data.json", type=["json"])
    ceiling_json = st.file_uploader("ceiling_data.json", type=["json"])

    st.markdown("---")
    st.markdown("### ‚ë¢ ÏòµÏÖò ÏÑ†ÌÉù")

# Load data
price_df: Optional[pd.DataFrame] = None
if pricebook_file is not None:
    try:
        price_df = load_pricebook_from_excel(pricebook_file.read())
        st.sidebar.success(f"Îã®Í∞ÄÌëú Î°úÎìú ÏôÑÎ£å: {len(price_df)}Ìñâ")
    except Exception as e:
        st.sidebar.error(f"Îã®Í∞ÄÌëú Î°úÎìú Ïã§Ìå®: {e}")

def safe_load_json(f) -> Optional[dict]:
    if f is None:
        return None
    try:
        return json.load(f)
    except Exception as e:
        st.error(f"JSON Î°úÎìú Ïã§Ìå®: {e}")
        return None

floor_data = safe_load_json(floor_json)
wall_data = safe_load_json(wall_json)
ceiling_data = safe_load_json(ceiling_json)

# ----------------------------
# UI: Îã®Ïùº/Îã§Ï§ë ÏÑ†ÌÉù Í∑∏Î£π
# ----------------------------
# Îã®Ïùº ÏÑ†ÌÉù (Radio)
single_choice_specs = {
    "ÎÉâÏò®ÏàòÎ∞∞Í¥Ä": ["PB ÎèÖÎ¶ΩÎ∞∞Í¥Ä","PB ÏÑ∏ÎåÄ ÏÑ∏Ìä∏ Î∞∞Í¥Ä","PB+Ïù¥Ï§ëÍ¥Ä(Ïò§ÌîàÏàòÏ†ÑÌï®)"],
    "Î¨∏ÌãÄÍ∑úÍ≤©": ["110m/m","130m/m","140m/m","155m/m","175m/m","195m/m","210m/m","230m/m"],
    "ÎèÑÍ∏∞Î•ò(ÏÑ∏Î©¥Í∏∞/ÏàòÏ†Ñ)": ["Í∏¥Îã§Î¶¨ ÏÑ∏Î©¥Í∏∞ ÏàòÏ†Ñ(ÏõêÌôÄ)","Í∏¥Îã§Î¶¨ ÏÑ∏Î©¥ÏÉ§Ïõå Í≤∏Ïö©ÏàòÏ†Ñ(ÏõêÌôÄ)","Î∞òÎã§Î¶¨ ÏÑ∏Î©¥Í∏∞ ÏàòÏ†Ñ(ÏõêÌôÄ)","Î∞òÎã§Î¶¨ ÏÑ∏Î©¥ÏÉ§Ïõå Í≤∏Ïö©ÏàòÏ†Ñ(ÏõêÌôÄ)"],
    "ÎèÑÍ∏∞Î•ò(Î≥ÄÍ∏∞)": ["ÏñëÎ≥ÄÍ∏∞ Ìà¨ÌîºÏä§","ÏñëÎ≥ÄÍ∏∞ Ï§ÄÌîºÏä§"],
    "ÏùÄÍ≤Ω": ["ÏûàÏùå","ÏóÜÏùå"],
    "ÏöïÏã§Ïû•": ["PSÏû•(600*900)","Ïä¨ÎùºÏù¥Îî© ÏöïÏã§Ïû•"],
    "Ïπ∏ÎßâÏù¥": ["ÏÉ§ÏõåÎ∂ÄÏä§","ÏÉ§ÏõåÌååÌã∞ÏÖò"],
    "ÏöïÏ°∞": ["SQÏöïÏ°∞","ÏÑ∏ÎùºÎØπ ÏöïÏ°∞"],
    "ÌôòÍ∏∞Î•ò": ["ÌôòÌíçÍ∏∞","ÌõÑÎ†âÏãúÎ∏î Ìò∏Ïä§, ÏÑúÏä§Î∞¥Îìú"],
}

multi_choice_specs = {
    "Î¨∏ÏÑ∏Ìä∏": ["PVC 4Î∞©ÌãÄ (130 ~ 230Î∞î)","ABS Î¨∏Ïßù","ÎèÑÏñ¥ÎùΩ","Í≤ΩÏ≤©","ÎèÑÏñ¥Ïä§ÌÜ†Ìçº"],
    "Ïï°ÏÑ∏ÏÑúÎ¶¨": ["ÏàòÍ±¥Í±∏Ïù¥","Ìú¥ÏßÄÍ±∏Ïù¥","Îß§Î¶ΩÌòï Ìú¥ÏßÄÍ±∏Ïù¥","ÏΩîÎÑàÏÑ†Î∞ò","ÏùºÏûê Ïú†Î¶¨ÏÑ†Î∞ò","Ï≤≠ÏÜåÏÜî","2Îã® ÏàòÍ±¥ÏÑ†Î∞ò"],
    "ÏàòÏ†Ñ": ["ÏÉ§ÏõåÏàòÏ†Ñ","Ïä¨ÎùºÏù¥ÎìúÎ∞î","Î†àÏù∏ ÏÉ§ÏõåÏàòÏ†Ñ","ÏÑ†Î∞òÌòï Î†àÏù∏ ÏÉ§ÏõåÏàòÏ†Ñ","Ï≤≠ÏÜåÍ±¥","ÏÑ∏ÌÉÅÍ∏∞ ÏàòÏ†Ñ"],
    "ÏöïÏã§Îì±": ["Ï≤úÏû• Îß§Î¶ΩÎì±(ÏÇ¨Í∞Å)","Ï≤úÏû• Îß§Î¶ΩÎì±(ÏõêÌòï)","Î≤ΩÎ∂ÄÎì±"],
}

with st.expander("Îã®Ïùº ÏÑ†ÌÉù (Radio)", expanded=True):
    single_selections = {}
    for group, options in single_choice_specs.items():
        single_selections[group] = st.radio(group, options, horizontal=True, index=0)

with st.expander("Îã§Ï§ë ÏÑ†ÌÉù (Checkbox)", expanded=True):
    multi_selections = {}
    for group, options in multi_choice_specs.items():
        picked = []
        cols = st.columns(min(4, len(options)))
        for i, opt in enumerate(options):
            with cols[i % len(cols)]:
                if st.checkbox(f"{group}: {opt}"):
                    picked.append(opt)
        multi_selections[group] = picked

# ----------------------------
# Í≤¨Ï†ÅÏÑú ÏÉùÏÑ±
# ----------------------------
rows: List[Dict[str,Any]] = []
warnings: List[str] = []

if price_df is None:
    st.warning("Îã®Í∞ÄÌëú(ÏóëÏÖÄ)Î•º Î®ºÏ†Ä ÏóÖÎ°úÎìúÌïòÏÑ∏Ïöî.")
else:
    # 1) Î∞îÎã•Ìåê
    if floor_data:
        material = str(floor_data.get("Ïû¨Ïßà","")).upper()
        spec_text = str(floor_data.get("Í∑úÍ≤©","")).strip()
        qty = float(floor_data.get("ÏàòÎüâ", 1))
        unit_price = float(floor_data.get("Îã®Í∞Ä", 0))
        senior = bool(floor_data.get("Ï£ºÍ±∞ÏïΩÏûê", False))

        # ÌíàÎ™© 'Î∞îÎã•Ìåê' Î≥∏Ï≤¥
        add_row(rows, "Î∞îÎã•Ìåê", material, qty, unit_price)

        # Î∂ÄÏû¨Î£å ÏûêÎèô Ìè¨Ìï®
        if material in ["GRP","SMC/FRP","PP/PE","PVE"]:
            # PVE == PP/PE ÎèôÏùº Ï≤òÎ¶¨
            if material == "PVE":
                Î∂ÑÎ•ò = "PP/PE Î∂ÄÏû¨Î£å"
            elif material == "SMC/FRP":
                Î∂ÑÎ•ò = "SMC/FRP Î∂ÄÏû¨Î£å"
            elif material == "PP/PE":
                Î∂ÑÎ•ò = "PP/PE Î∂ÄÏû¨Î£å"
            else:
                Î∂ÑÎ•ò = "GRPÎ∂ÄÏû¨Î£å"
            add_all_by_category(rows, price_df, "Î∞îÎã•Ìåê", Î∂ÑÎ•ò)
        else:
            warnings.append(f"Î∞îÎã•Ìåê Ïû¨Ïßà '{material}'Ïóê ÎåÄÌïú Î∂ÑÎ•ò Îß§ÌïëÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")

        # Ï£ºÍ±∞ÏïΩÏûê Ï∂îÍ∞Ä
        if senior:
            for spec in ["Îß§Î¶ΩÌòï Ìú¥ÏßÄÍ±∏Ïù¥(ÎπÑÏÉÅÌè∞)","LÌòï ÏÜêÏû°Ïù¥","„Ö°Ìòï ÏÜêÏû°Ïù¥","Ï†ëÏùòÏãù ÏùòÏûê"]:
                rec = find_item(price_df, "Ïï°ÏÑ∏ÏÑúÎ¶¨", "Ï£ºÍ±∞ÏïΩÏûê", spec_contains=spec)
                if rec is not None:
                    add_row(rows, "Ïï°ÏÑ∏ÏÑúÎ¶¨", spec, rec.get("ÏàòÎüâ",1) or 1, rec.get("Îã®Í∞Ä",0))
                else:
                    add_row(rows, "Ïï°ÏÑ∏ÏÑúÎ¶¨", spec, 1, 0)
                    warnings.append(f"Ï£ºÍ±∞ÏïΩÏûê '{spec}' Îã®Í∞Ä ÎØ∏Î∞úÍ≤¨ ‚Üí 0 Ï≤òÎ¶¨")

    # 2) Î≤ΩÌåê & ÌÉÄÏùº
    if wall_data:
        # PUÎ≤ΩÌåê
        wall_spec = "PUÎ≤ΩÌåê"
        rec = find_item(price_df, "Î≤ΩÌåê", "PUÌÉÄÏùº Î≤ΩÏ≤¥", spec_contains="PUÎ≤ΩÌåê")
        qty = float(wall_data.get("Ï¥ùÍ∞úÏàò", 0))
        unit_price = None
        if rec is not None:
            unit_price = rec.get("Îã®Í∞Ä", None)
        else:
            # fallback to wall_data['Îã®Í∞Ä']
            unit_price = float(wall_data.get("Îã®Í∞Ä", 0))
            warnings.append("Î≤ΩÌåê(PUÎ≤ΩÌåê) Îã®Í∞ÄÎ•º ÏóëÏÖÄÏóêÏÑú Ï∞æÏßÄ Î™ªÌï¥ wall_data Îã®Í∞ÄÎ°ú ÎåÄÏ≤¥ÌñàÏäµÎãàÎã§.")
        add_row(rows, "Î≤ΩÌåê", wall_spec, qty, unit_price)

        # Î≤ΩÌÉÄÏùº & Î∞îÎã•ÌÉÄÏùº Í∑úÍ≤© Ïó∞Îèô
        tile_str = str(wall_data.get("Î≤ΩÌÉÄÏùº","")).replace("√ó","x").replace(" ", "")
        wall_tile_spec = None
        if tile_str in ["250x400","250*400"]:
            wall_tile_spec = "Î≤ΩÌÉÄÏùº 250*400"
            floor_tile_spec = "Î∞îÎã•ÌÉÄÏùº 200*200"
        else:
            # default 300x600
            wall_tile_spec = "Î≤ΩÌÉÄÏùº 300*600"
            floor_tile_spec = "Î∞îÎã•ÌÉÄÏùº 300*300"

        # Î≤ΩÌÉÄÏùº
        rec = find_item(price_df, "ÌÉÄÏùº", "PUÌÉÄÏùº Î≤ΩÏ≤¥ ÌÉÄÏùº", spec_contains=wall_tile_spec)
        if rec is not None:
            add_row(rows, "ÌÉÄÏùº", wall_tile_spec, rec.get("ÏàòÎüâ",1) or 1, rec.get("Îã®Í∞Ä",0))
        else:
            add_row(rows, "ÌÉÄÏùº", wall_tile_spec, 1, 0)
            warnings.append(f"'{wall_tile_spec}' Îã®Í∞Ä ÎØ∏Î∞úÍ≤¨ ‚Üí 0 Ï≤òÎ¶¨")

        # Î∞îÎã•ÌÉÄÏùº
        # Î∂ÑÎ•òÎäî 'Î∞îÎã•ÌÉÄÏùº'
        rec = find_item(price_df, "ÌÉÄÏùº", "Î∞îÎã•ÌÉÄÏùº", spec_contains=floor_tile_spec.split()[-1])
        if rec is None:
            # try exact spec text
            rec = find_item(price_df, "ÌÉÄÏùº", "Î∞îÎã•ÌÉÄÏùº", spec_contains=floor_tile_spec)
        if rec is not None:
            add_row(rows, "ÌÉÄÏùº", floor_tile_spec, rec.get("ÏàòÎüâ",1) or 1, rec.get("Îã®Í∞Ä",0))
        else:
            add_row(rows, "ÌÉÄÏùº", floor_tile_spec, 1, 0)
            warnings.append(f"'{floor_tile_spec}' Îã®Í∞Ä ÎØ∏Î∞úÍ≤¨ ‚Üí 0 Ï≤òÎ¶¨")

    # 3) Ï≤úÏû•Ìåê
    if ceiling_data:
        material = str(ceiling_data.get("Ïû¨Ïßà","")).upper()
        body = ceiling_data.get("Î∞îÎîîÌåêÎÑ¨", {}) or {}
        side = ceiling_data.get("ÏÇ¨Ïù¥ÎìúÌåêÎÑ¨", {}) or {}
        total_cnt = float(ceiling_data.get("Ï¥ùÍ∞úÏàò", 0))
        hole_cnt = float(ceiling_data.get("Ï≤úÍ≥µÍµ¨", 0))

        # Î©îÏù∏ Ìåê
        if material == "ABS":
            rec = find_item(price_df, "Ï≤úÏû•Ìåê", None, spec_contains="ABSÏ≤úÏû•Ìåê")
            add_row(rows, "Ï≤úÏû•Ìåê", "ABSÏ≤úÏû•Ìåê", total_cnt or (body.get("Í∞úÏàò",0)+side.get("Í∞úÏàò",0)), rec.get("Îã®Í∞Ä",0) if rec is not None else 0)
            if rec is None:
                warnings.append("ABSÏ≤úÏû•Ìåê Îã®Í∞Ä ÎØ∏Î∞úÍ≤¨ ‚Üí 0 Ï≤òÎ¶¨")
        elif material == "GRP":
            rec = find_item(price_df, "Ï≤úÏû•Ìåê", None, spec_contains="GRPÏ≤úÏû•Ìåê")
            add_row(rows, "Ï≤úÏû•Ìåê", "GRPÏ≤úÏû•Ìåê", total_cnt or (body.get("Í∞úÏàò",0)+side.get("Í∞úÏàò",0)), rec.get("Îã®Í∞Ä",0) if rec is not None else 0)
            if rec is None:
                warnings.append("GRPÏ≤úÏû•Ìåê Îã®Í∞Ä ÎØ∏Î∞úÍ≤¨ ‚Üí 0 Ï≤òÎ¶¨")
        else:
            add_row(rows, "Ï≤úÏû•Ìåê", material, total_cnt, 0)
            warnings.append(f"Ï≤úÏû•Ìåê Ïû¨Ïßà '{material}' Îã®Í∞Ä ÎØ∏Î∞úÍ≤¨ ‚Üí 0 Ï≤òÎ¶¨")

        # ÏÑ∏Î∂Ä ÏàòÎüâ ÌëúÍ∏∞ (Ï†ïÎ≥¥Ïö© Ìï≠Î™©)
        if body.get("Í∞úÏàò",0):
            add_row(rows, "Ï≤úÏû•Ìåê", f"Î∞îÎîîÌåêÎÑ¨ ({body.get('Ï¢ÖÎ•ò','')})", float(body.get("Í∞úÏàò",0)), float(ceiling_data.get("Îã®Í∞Ä",0)))
        if side.get("Í∞úÏàò",0):
            add_row(rows, "Ï≤úÏû•Ìåê", f"ÏÇ¨Ïù¥ÎìúÌåêÎÑ¨ ({side.get('Ï¢ÖÎ•ò','')})", float(side.get("Í∞úÏàò",0)), float(ceiling_data.get("Îã®Í∞Ä",0)))
        if hole_cnt:
            add_row(rows, "Ï≤úÏû•Ìåê", "Ï≤úÍ≥µÍµ¨", hole_cnt, 0)

    # 4) Îã®Ïùº ÏÑ†ÌÉù Í∑∏Î£π Î∞òÏòÅ
    for group, spec in single_selections.items():
        if group == "ÏùÄÍ≤Ω" and spec == "ÏóÜÏùå":
            continue
        # ÌíàÎ™©ÏùÄ groupÏóêÏÑú ÌååÏÉù
        ÌíàÎ™© = group.split("(")[0]  # Í¥ÑÌò∏ Ï†úÍ±∞
        rec = find_item(price_df, ÌíàÎ™©, None, spec_contains=spec)
        if rec is None:
            # ÏùºÎ∂Ä Í∑∏Î£πÏùÄ ÌíàÎ™©Î™ÖÏù¥ ÏãúÌä∏ÏôÄ Îã§Î•º Ïàò ÏûàÏñ¥ Î≥¥Ï°∞ Îß§Ìïë
            alt_map = {
                "ÎèÑÍ∏∞Î•ò(ÏÑ∏Î©¥Í∏∞/ÏàòÏ†Ñ)": ("ÎèÑÍ∏∞Î•ò", None),
                "ÎèÑÍ∏∞Î•ò(Î≥ÄÍ∏∞)": ("ÎèÑÍ∏∞Î•ò", None),
            }
            if group in alt_map:
                ÌíàÎ™©2, Î∂ÑÎ•ò2 = alt_map[group]
                rec = find_item(price_df, ÌíàÎ™©2, Î∂ÑÎ•ò2, spec_contains=spec)
                ÌíàÎ™© = ÌíàÎ™©2
        if rec is not None:
            add_row(rows, ÌíàÎ™©, spec, rec.get("ÏàòÎüâ",1) or 1, rec.get("Îã®Í∞Ä",0))
        else:
            add_row(rows, ÌíàÎ™©, spec, 1, 0)
            warnings.append(f"[Îã®ÏùºÏÑ†ÌÉù] '{group} - {spec}' Îã®Í∞Ä ÎØ∏Î∞úÍ≤¨ ‚Üí 0 Ï≤òÎ¶¨")

    # 5) Îã§Ï§ë ÏÑ†ÌÉù Í∑∏Î£π Î∞òÏòÅ
    for group, specs in multi_selections.items():
        for spec in specs:
            rec = find_item(price_df, group, None, spec_contains=spec)
            if rec is None:
                # ÏùºÎ∂Ä Í∑∏Î£πÏùÄ ÌíàÎ™© Î™ÖÏù¥ Îã§Î¶Ñ
                alt_map = {
                    "Î¨∏ÏÑ∏Ìä∏": "Î¨∏ÏÑ∏Ìä∏",
                    "Ïï°ÏÑ∏ÏÑúÎ¶¨": "Ïï°ÏÑ∏ÏÑúÎ¶¨",
                    "ÏàòÏ†Ñ": "ÏàòÏ†Ñ",
                    "ÏöïÏã§Îì±": "ÏöïÏã§Îì±",
                }
                ÌíàÎ™©2 = alt_map.get(group, group)
                rec = find_item(price_df, ÌíàÎ™©2, None, spec_contains=spec)
                if rec is None:
                    add_row(rows, ÌíàÎ™©2, spec, 1, 0)
                    warnings.append(f"[Îã§Ï§ëÏÑ†ÌÉù] '{group} - {spec}' Îã®Í∞Ä ÎØ∏Î∞úÍ≤¨ ‚Üí 0 Ï≤òÎ¶¨")
                    continue
                add_row(rows, ÌíàÎ™©2, spec, rec.get("ÏàòÎüâ",1) or 1, rec.get("Îã®Í∞Ä",0))
            else:
                add_row(rows, group, spec, rec.get("ÏàòÎüâ",1) or 1, rec.get("Îã®Í∞Ä",0))

    # 6) Í≥µÌÜµÏûêÏû¨ Ï†ÑÎ∂Ä Ìè¨Ìï®
    commons = price_df[price_df["ÌíàÎ™©"]=="Í≥µÌÜµÏûêÏû¨"]
    for _, r in commons.iterrows():
        add_row(rows, "Í≥µÌÜµÏûêÏû¨", str(r["ÏÇ¨Ïñë Î∞è Í∑úÍ≤©"]), r["ÏàòÎüâ"] if pd.notna(r["ÏàòÎüâ"]) else 1, r["Îã®Í∞Ä"] if pd.notna(r["Îã®Í∞Ä"]) else 0)

# ----------------------------
# Í≤∞Í≥º Ìëú
# ----------------------------
if rows:
    est_df = pd.DataFrame(rows, columns=["ÌíàÎ™©","ÏÇ¨Ïñë Î∞è Í∑úÍ≤©","ÏàòÎüâ","Îã®Í∞Ä","Í∏àÏï°"])
    est_df["ÏàòÎüâ"] = pd.to_numeric(est_df["ÏàòÎüâ"], errors="coerce").fillna(0).astype(float)
    est_df["Îã®Í∞Ä"] = pd.to_numeric(est_df["Îã®Í∞Ä"], errors="coerce").fillna(0).astype(float)
    est_df["Í∏àÏï°"] = (est_df["ÏàòÎüâ"] * est_df["Îã®Í∞Ä"]).round(0)

    st.subheader("Í≤¨Ï†ÅÏÑú ÎØ∏Î¶¨Î≥¥Í∏∞")
    st.dataframe(est_df, use_container_width=True)

    totals = est_df.groupby("ÌíàÎ™©", dropna=False)["Í∏àÏï°"].sum().reset_index().sort_values("Í∏àÏï°", ascending=False)
    st.markdown("#### ÌíàÎ™©Î≥Ñ Ìï©Í≥Ñ")
    st.dataframe(totals, use_container_width=True)

    grand_total = est_df["Í∏àÏï°"].sum()
    st.metric("Ï¥ù Í∏àÏï°", f"{grand_total:,.0f} Ïõê")

    # Îã§Ïö¥Î°úÎìú
    @st.cache_data(show_spinner=False)
    def df_to_excel_bytes(df: pd.DataFrame) -> bytes:
        import io
        from pandas import ExcelWriter
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
            df.to_excel(writer, index=False, sheet_name="Í≤¨Ï†ÅÏÑú")
        return output.getvalue()

    xlsx_bytes = df_to_excel_bytes(est_df)
    st.download_button("Í≤¨Ï†ÅÏÑú Excel Îã§Ïö¥Î°úÎìú", data=xlsx_bytes, file_name="estimate.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

if warnings:
    with st.expander("Í≤ΩÍ≥†/Ï∞∏Í≥†", expanded=False):
        for w in warnings:
            st.warning(w)

